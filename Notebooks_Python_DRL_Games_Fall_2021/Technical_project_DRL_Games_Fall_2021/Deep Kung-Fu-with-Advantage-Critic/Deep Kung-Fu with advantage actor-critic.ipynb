{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3C.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ultan-Kearns/Artificial-Intelligence-CA/blob/master/Notebooks_Python_DRL_Games_Fall_2021/Technical_project_DRL_Games_Fall_2021/Deep%20Kung-Fu-with-Advantage-Critic/Deep%20Kung-Fu%20with%20advantage%20actor-critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjC4uqSP17ai"
      },
      "source": [
        "# Deep Kung-Fu with advantage actor-critic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRXcuuh3qB6q"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWdlrlePjq-g",
        "outputId": "b96b20e8-0ef6-4fb6-bdd2-dda5f14e9e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcOgo4xwj4PJ",
        "outputId": "90185e35-93b4-40c6-9a51-06e45013b8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install python-opengl -y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (590 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aS0God8kBDE",
        "outputId": "bbf3487d-21c7-41da-a09c-df73622f142a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt install xvfb -y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 784 kB in 1s (883 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 157584 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZuEBujtkKoj",
        "outputId": "9875f2d8-ee97-4e63-c4ed-a440721cc6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-1.1 pyvirtualdisplay-2.2\n",
            "Collecting piglet\n",
            "  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n",
            "Collecting piglet-templates\n",
            "  Downloading piglet_templates-1.2.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (21.4.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (3.0.7)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (2.0.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.37.1)\n",
            "Installing collected packages: piglet-templates, piglet\n",
            "Successfully installed piglet-1.0.0 piglet-templates-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfq6FvJ9kW1G",
        "outputId": "1fe7910f-b3bc-4ffa-c010-948f796d9bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f8e21eadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW0KjeOVkc88"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from IPython.core import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "#If you are running on a server, launch xvfb to record game videos\n",
        "#Please make sure you have xvfb installed\n",
        "import os\n",
        "if os.environ.get(\"DISPLAY\") is str and len(os.environ.get(\"DISPLAY\"))!=0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTsbpF4In-3c"
      },
      "source": [
        "# Atari Environment\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w1HpxbzX81j",
        "outputId": "c0253c9d-c522-4375-c057-988496563d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install scipy==1.1.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR12anpKlcId",
        "outputId": "cc937a2d-cea9-4cc1-9e7a-1eaa0bef236d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install -y python-numpy python-dev cmake zlib1g-dev libjpeg-dev xvfb libav-tools xorg-dev python-opengl libboost-all-dev libsdl2-dev swig"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libav-tools is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  ffmpeg\n",
            "\n",
            "E: Package 'libav-tools' has no installation candidate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl5urImpnSBQ",
        "outputId": "ef643b4a-2b13-4eaf-a17f-6ac28b56ca7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install \"gym[atari,accept-rom-license]\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'accept-rom-license'\u001b[0m\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.1.2.30)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[accept-rom-license,atari]) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[accept-rom-license,atari]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount gdrive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxKeJXPYXjC",
        "outputId": "e39b7863-b428-4227-9983-64ff72af75fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  # Atari depreacated installing ale-py instead\n",
        "  !python -m pip install ale-py\n",
        "  !pip install gym[atari] \n",
        "  from ale_py import ALEInterface \n",
        "  ale = ALEInterface()\n",
        "\n",
        "  !ale-import-roms '/content/gdrive/My Drive/roms'\n",
        "\n",
        "except:\n",
        "  print('Couldn\\'t find rom')"
      ],
      "metadata": {
        "id": "8okmCM_9D8y6",
        "outputId": "913da672-fa22-4159-d947-090edb160a02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.7/dist-packages (0.7.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py) (5.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ale-py) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from ale-py) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->ale-py) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->ale-py) (3.10.0.2)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari]) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             breakout /content/gdrive/My Drive/roms/Breakout.bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       kung_fu_master /content/gdrive/My Drive/roms/KungFuMaster.bin\n",
            "\n",
            "\n",
            "\n",
            "Imported 2 / 2 ROMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# im resize depracated using scikit-image library instead\n",
        "!python -m pip install -U scikit-image"
      ],
      "metadata": {
        "id": "nRNtTm9jIGVr",
        "outputId": "4fda4ea9-b481-4003-b141-071cd636d45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.19.5)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.2.0)\n",
            "Collecting scipy>=1.4.1\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.7)\n",
            "Installing collected packages: scipy, scikit-image\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.19.1 scipy-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Had issue with preprocess atari so needed code from Github\n",
        "# Reference: https://github.com/sshkhr/Practical_RL/blob/master/week6_policy_based/atari_util.py\n",
        "# Code by https://github.com/sshkhr \n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Auxilary files for those who wanted to solve breakout with CEM or policy gradient\"\"\"\n",
        "import numpy as np\n",
        "import gym\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from gym.core import Wrapper\n",
        "from gym.spaces.box import Box\n",
        "\n",
        "class PreprocessAtari(Wrapper):\n",
        "    def __init__(self, env, height=42, width=42, color=False, crop=lambda img: img, \n",
        "                 n_frames=4, dim_order='theano', reward_scale=1,):\n",
        "        \"\"\"A gym wrapper that reshapes, crops and scales image into the desired shapes\"\"\"\n",
        "        super(PreprocessAtari, self).__init__(env)\n",
        "        assert dim_order in ('theano', 'tensorflow')\n",
        "        self.img_size = (height, width)\n",
        "        self.crop=crop\n",
        "        self.color=color\n",
        "        self.dim_order = dim_order\n",
        "        self.reward_scale = reward_scale\n",
        "        \n",
        "        n_channels = (3 * n_frames) if color else n_frames\n",
        "        obs_shape = [n_channels,height,width] if dim_order == 'theano' else [height,width,n_channels]\n",
        "        self.observation_space = Box(0.0, 1.0, obs_shape)\n",
        "        self.framebuffer = np.zeros(obs_shape, 'float32')\n",
        "        \n",
        "    def reset(self):\n",
        "        \"\"\"resets breakout, returns initial frames\"\"\"\n",
        "        self.framebuffer = np.zeros_like(self.framebuffer)\n",
        "        self.update_buffer(self.env.reset())\n",
        "        return self.framebuffer\n",
        "    \n",
        "    def step(self,action):\n",
        "        \"\"\"plays breakout for 1 step, returns frame buffer\"\"\"\n",
        "        new_img, reward, done, info = self.env.step(action)\n",
        "        self.update_buffer(new_img)\n",
        "        return self.framebuffer, reward * self.reward_scale, done, info\n",
        "    \n",
        "    ### image processing ###\n",
        "    \n",
        "    def update_buffer(self,img):\n",
        "        img = self.preproc_image(img)\n",
        "        offset = 3 if self.color else 1\n",
        "        if self.dim_order == 'theano':\n",
        "            axis = 0\n",
        "            cropped_framebuffer = self.framebuffer[:-offset]\n",
        "        else:\n",
        "            axis = -1\n",
        "            cropped_framebuffer = self.framebuffer[:,:,:-offset]\n",
        "        self.framebuffer = np.concatenate([img, cropped_framebuffer], axis = axis)\n",
        "\n",
        "    def preproc_image(self, img):\n",
        "        \"\"\"what happens to the observation\"\"\"\n",
        "        img = self.crop(img)\n",
        "        img = skimage.transform.resize(img, self.img_size)\n",
        "        if not self.color:\n",
        "            img = img.mean(-1, keepdims=True)\n",
        "        if self.dim_order == 'theano':\n",
        "            img = img.transpose([2,0,1]) # [h, w, c] to [c, h, w]\n",
        "        img = img.astype('float32') / 255.\n",
        "        return img"
      ],
      "metadata": {
        "id": "fCZdVhCN5lKK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMEwvBMNoRdt"
      },
      "source": [
        "# Deep Kung-Fu with advantage actor-critic\n",
        "\n",
        "---\n",
        "\n",
        "For starters, let's take a look at the game itself:\n",
        "\n",
        " * Image resized to 42x42 and grayscale to run faster\n",
        " * Rewards divided by 100 'cuz they are all divisible by 100\n",
        " * Agent sees last 4 frames of game to account for object velocity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRSoMY-Tkkmb",
        "outputId": "a58679cb-a123-4943-9881-16b493d9ba3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"KungFuMaster-v0\")\n",
        "    env = PreprocessAtari(env, height=42, width=42,\n",
        "                          crop = lambda img: img[60:-30, 5:],\n",
        "                          dim_order = 'tensorflow',\n",
        "                          color=False, n_frames=4,\n",
        "                          reward_scale = 0.01)\n",
        "    return env\n",
        "\n",
        "env = make_env()\n",
        "\n",
        "obs_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"Observation shape:\", obs_shape)\n",
        "print(\"Num actions:\", n_actions)\n",
        "print(\"Action names:\", env.env.env.get_action_meanings())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: obs_type \"image\" should be replaced with the image type, one of: rgb, grayscale\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation shape: (42, 42, 4)\n",
            "Num actions: 18\n",
            "Action names: ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ems5qHMeZU0q"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pd1KapnM0A",
        "outputId": "f5b50258-8e22-4ba3-e9ec-961ae411d4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "s = env.reset()\n",
        "for _ in range(100):\n",
        "    s, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "plt.title('Game image')\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()\n",
        "\n",
        "plt.title('Agent observation (4-frame buffer)')\n",
        "plt.imshow(s.transpose([0,2,1]).reshape([42,-1]))\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAEICAYAAAAX2cvZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3gc1bmH3292teqSLVnGtlzlBphiwBgDBmx6C05IADsJJIELKZAC5FJCuJd0bigJpJA49FzAIaEZLg6hGEzAGAwugAuWuywXuUiyZbXd+e4fM1qvZK0t7a52dlfnfZ55duecKb/Rzk+nzJnviKpiMBi6h+W1AIMhHTHGMRhiwBjHYIgBYxyDIQaMcQyGGDDGMRhiwBgnAxGRoSKyR0R8XmvJVIxx4kBEpovIAhFpEJFt7vfviIh4qUtVN6hqgaqGvNSRyRjjxIiI3AjcB9wFDAAOAb4FnAwEPJRmSAaqapZuLkAx0AB88SDbXQAsAuqBjcAdEXnDAQW+4ebtwjHe8cBSoBb4fYfjXQksd7d9BRgW5bxtx/a7628CPwfeBfYALwKlwBOutg+A4RH73+dqqgc+BE6JyMsFHnM1LAduAqoi8gcBzwA1wFrge17/Xj1yD3gtIB0X4Fwg2HZjHmC7KcCROCX7UcBW4PNuXtvN/ScgBzgbaAKeB/oD5cA24DR3+2lAJXAY4Ad+DLwb5bydGacSGOmafhnwGXCme6zHgUci9v+qayw/cCOwBchx8+4E3gL6AoNdk1e5eZZrtP/CKXUrgDXAOV7/Zgm/B7wWkI6Le2Nt6ZD2rltKNAKnRtnvt8Bv3O9tN3d5RP4O4LKI9WeAH7jf5wBXReRZwF46KXWiGOe2iPx7gDkR658DFh/gencBR7vf2xkB+I8I45wAbOiw762RpsyUxbRxYmMH0E9E/G0JqnqSqvZx8ywAETlBROaKSI2I1OFUxfp1ONbWiO+NnawXuN+HAfeJSK2I1AI7AcEpmbpCV8+DiPxQRJaLSJ17ruII3YNwqnFtRH4fBgxq0+ju+yOc9l9GYYwTG/OBZpzq04F4EpgNDFHVYpxqWaw9bhuBb6pqn4glV1XfjfF4nSIip+C0Wy4F+rr/DOrYp3szThWtjSEdNK7toLFQVc9PpMZUwBgnBlS1FvgJ8EcR+ZKIFIqIJSLjgfyITQuBnaraJCITgS/Hcdo/AbeKyDgAESkWkUviOF40CnHabzWAX0T+CyiKyH/a1dFXRMqB6yLy3gd2i8jNIpIrIj4ROUJEju8BnZ5ijBMjqvpr4Aac/85b3eXPwM047R2A7wA/FZHdOA3mp+M433PA/wCzRKQe+AQ4L+YLiM4rwD9xOg/W43RYRFbHfgpU4fSYvQb8A6f0RZ3nRhcC49387cCDOFW9jELcBpzBEBMi8m1guqqe5rWWZGJKHEO3EJGBInKyWzUdi9Nd/ZzXupKN/+CbGAztCOBUSUfgdL/PAv7oqSIP6LGqmoici/ME2gc8qKp39siJDAYP6BHjuKNyPwPOwmlIfgDMUNVlCT+ZweABPVVVmwhUquoaABGZhfPMo1PjiIjpoTCkIttVtayzjJ7qHCinfRdmFR2ecIvINSKyUEQW9pAGgyFe1kfL8KxzQFVnAjPBlDiG9KOnSpxNtB+KMdhNMxgygp4yzgfAaBEZISIBYDrOmC2DISPokaqaqgZF5Dqc4Rs+4GFV/bQnzmUweEFKDLkxbRxDivKhqk7oLMMMuTEYYiAthtyceeaZlJSUeC3D0Mt4+unog9nTwjilpaUMGDDAaxkGQ5i0ME6ymDx5Mnl5eSxYsIC6urp2eSNHjmTkyJHh9ZqaGhYtWhRez87O5rTT9o2sV1VeffXV8PpZZ51FZ+HW5s+fz+7duxN5GYYkYIzjctJJJzF69GgCgQBLlixpZ5xRo0Yxfvx4GhoaWL16Nf3792fcuHEALFq0iNzcXE4++WTKy8t55513wvtNmTKFN998E4Dhw4djWRbz5s0jFNoXJ7ClpSU5F2hIKMY4Ljt27Gh3Q0dSVlZGaWkpVVVVfPbZZwSDQcaNG8eQIUNYtGgRgUCAkSNH0tTUxGeffRbeLysra79jVVZW0tra2mPXYUgOxjguK1eu5JhjjiE3N3e/vI0bN4bbWRMmTKBv376dHsPv9zNhwr7ey4UL9x+Gd+yxx4YN+vHHH9Pc3JygKzAkE2OcLlBVVQVAeXk5Pp8Py4rei9+Wf+SRR9LS0sLSpUsBwp9t2xx++OH4fD6WLl1KY2Njz16AIeEY43SB/v3709TUxIIFCwCoqKhg+PDh+20XDAZZsGABlmVx1FFHMWnSpLBh6urqWLlyZVuQvnC7afXq1cY4aYgxjsuwYcPCbZLy8nLq6+vDN3RxcTFFRUUUFzvBWg455BAaGhrYtMkZt9rS0sK6desYNGgQI0eOxLIsVJXVq1eHj3/KKacQCoWwbRtwqnXr1683VbU0xRjHpaKigpqaGsApYTZs2BA2zqpVqxg1ahSjR48Ob79ixQo+/PBDABobG3nzzTeZOnVqeJsNGzbw+uuvh7ffsGFDu+7srVu38vbbb9PQ0NDj12ZIPGkxVu2yyy4zD0ANSee+++4zY9UMhkRiqmophOQLEtg3ukCbFd3rfY3AsD/GOCmC5Ap55+XhH+KHFpBsoWVFC41vNKJNxjyphjFOipB/YT5Zo7JomNNAy+IWck7OIffUXBDY+397vZZn6IBp4xgMMRCzcURkiDtp0jIR+VREvu+m3yEim0Rksbtk3NwoBkM8VbUgcKOqfiQihcCHItI2jv43qnp3/PIMhtQkZuOo6mac2blQ1d0ispyuT6tn6ISOz9RS4RmboXMS0sYRkeHAMcACN+k6EVkqIg+LSKdDiU0kz/bs+fseWpe3knduHn1u6UPOKTk0L2w2HQMpSty9aiJSwL7ZketF5AHgZzizHv8MZ4bjKzvuZyJ57k/DCw3wgtcqDF0hrhJHRLJwTPOEqj4LoKpbVTWkqjbwF5wA7AZDRhFPr5oADwHLVfXeiPSBEZt9AWeuSoMho4inqnYycDnwsYgsdtN+BMxwZ19WYB3wzbgUGgwpSDy9av8G9g/bAi/HLseQahQXFzNt2rTweigU4oknnvBQUWrQa4fcjH/5ZSSiu/eTM86gNScnvL5x8yQa9vYPr/crWUG/vvsCcezZ25+qzZPC635/I6OG7QsHpQor11zU7pxjRryEZdnh9TUbTqeltSC8PuiQhRQVVMd5ZYmjpKSEyZMn8+yzzwJO8JFLLrmE6dOnM2vWLI/VeUuvNU52Q0P74rLDM5NgMIfWYH54PRRqH7FGbV+7fN2v8JV2+Z3RGsxtt41tp9bPUVdXx9y5c9mzZw/gGEdEKCws9FiZ96TWL2VIKUKhUDhYYnZ2NhdccAGhUIjnn3/eY2XeYwZ5GrpEa2srCxcuxLIsTjjhBK/leI4xjiEqRUVFTJ48GQDbttm8eTMiwqBBgzxW5j29tqq2emL757KhDlE3y0qW06doXXg9J2dXu/yc7FoGD5gfXresYIczaLt8ABG73frA/ovbtZ3ycnd0VX5SaG5uZseOHUydOhUAy7IIhULhsL69mV5rnO3Dhh0wvyB/6wHzs7Ia6Vu8Lmq+CAfMBygqSO1pUZubm1m9enW7YPHV1dVUVlZ6qCo16LXGMXSNlpYWli1b5rWMlMO0cQyGGOgVJY6IcNhhh4XXly1bxuGHH97uP+mYMWPw+50/x9q1aykrK2PXrl0UFhbS1NSEz+ejrKwMgPr6empraxk6dCjg/FeurKzE57M5+uj6JF5Z91mxooC9e3vFz96j9Iq/oGVZTJ48mcrKSkaNGsWyZcuYPHkyK1asCIeknThxIjU1NQwcOJAdO3ZwxBFHsHz5coYOHcrOnTvJzs6moqKC7du3Y1kWIsKECROoqamhqKiIyspKAgHlnHNqPL7aA7N5c44xTgLoNVW1jrGcO2PDhg3tYjmXlZVRULBvSExtbS1Llizhk0+cAd+NjY1s3LixZwQbUppeYxwR4cgjj6S6OvpYsLFjx4bnx9mxYweHHnoo+fn54SEnZWVllJfvezu8pKSEiRMnsm3btp4Vb0g5ek2Zraq89NJL7dL69euHbdvs2OE8P3njjTc4++yzAViwYAFFRUVs2LCBtWvXUlpaSnV1NdXV1eGxWq2trVRVVbF48WIMvYteYRxVpba2tl3arl27mDJlCgDPP/88dXV1hEIh6uvrCQadh5kNDQ3hOTobGxupqKjg9NNPZ+PGjaxdu5a1a9eyaNEiTjzxRObMmYNtw/bt+09fmEoEg529CWLoLma2AoMhCgearSARwTrWAbuBEBBU1QkiUgL8DRiO8xbopaq6K9oxDIZ0I1FVtamquj1i/RbgdVW9U0RucddvTtC54iJyJujW1laysrLaffr9/vAQk2AwGJ5dDZwOBlVFRLBtG5/PF67WAaCKP8rM1alC0OdzxgMZ4qKn2jjTgCnu98eAN0kR41x55ZXhm/2RRx7h8ssvZ9asWVx88cXMnj2bs88+mz59+qCqvP766wwbNoza2loCgQA+n4/a2loGDx4cnqV69uzZ4WNnBYOc+d57Xl1al3h3/HjqzItocZMI4yjwL7ed8mc3XtohbqRPgC3AIQk4T0JQVR5++OF2UTIvv/zydtu89NJLbNmyBXDmBp00yXlFesmSJeFtxPzX7tUk4jnOZFU9FjgPuFZETo3MVOcO3a/x71UkTxHh6quvPuA2F110EYMHDw6vq2o7o1VUVHDuuef2mEZD6hN3iaOqm9zPbSLyHE4Awq0iMlBVN7tx1vZ7QuhVJE9VZebMmfulRZYgL7zwAlu37nutYP78+WRnZ+P3+1mxYgUtLS2MHTuWOXPmJEu2IcWIN5JnvjtTASKSD5yNE4BwNvA1d7OvkUKBXUWEa665hmuuuQbLci7/scceazf787Rp07jmmmsYMWKEVzINKU5cz3FEpAJ4zl31A0+q6i9EpBR4GhgKrMfpjt55gOMk7TlOZMnSVtJ0/IzM7xYp8EysS5j2WZfosec4qroGOLqT9B3AGfEcu6eINpVGx8+YMDdkryEtRg5EPlsxGJJFa2trz40cSAbDvzKcvEF5Xssw9DKW/mpp1Ly0ME7J4BKKRxR7LcNgCJMWxvEv8ONflRZSDb2EtLgb1+esJycv5+AbGgxJIi2Mk90/m9xBuV7LMBjCpIVxsgJZBHICXsswGMKkhXHyi/IpKinyWobBECYtjFP1WhWBIlPiGFKHtDDOto9MFBlDapEWxjmrpITSgClxDMlllvtOVmekhXEuKCvj0PwDTwtoMCSaAxmn1wQkNBgSiTGOwRADaVFVyxuTRUGZaeMYksxH0bPSwjiDv13EqGP7eC3D0Nt4OHpWWhhnW01fNlb16/L2fn+Qvn1qsG2LHTu9CbAjovQrdRqX23cM9Ozl0H6lWxBRdu7qTyjk80RDcfFOAlnN7N5TTFOTN6+H5OY2UJBfT3NLDvX1feM+XszGEZGxONE626gA/gvoA1wNtE0U8yNVfTlmhcDvH7iYoj7jurx9afEWrr745+xtLOT+Wd+O59QxI2Jz89e/B8Cdj/wE8OZFvOu/8p9kBxp54O/fp25PqScaLjv7D4woX87L/z6PpatO9ETDhMPf5MwT/sFn64/m2TcOHOVoH49FzYnZOKq6EhgPICI+YBNO/IFvAL9R1btjPXa86C6w/2ATEhu8GhtqOxoAR4NHL7CGHrSx1UZz8KwryH7Rxg7ZaEA9q+PoEsVeaGP7FLLjP16iLuMMYLWqrk+FV5ylFKwZFr5GCx7xSIQF1g/dO/WPHmkAfNdZWNkW8lecCN8eYH3JwhpiIW8IrPBGgxwnWJMtrDUC/4z/eIkyznTgqYj160TkCmAhcGOyA67rdrB/4ZY4XvUp2I4GwNHgVYlzj1viFAHeNHGwn7Sxgzaal5j/9rGg7yv2WzZ2lkLBwbc/GHEX3iISAC4C/u4mPQCMxKnGbQbuibJfj0XylH5g/cTCd5OHj6ksR4P1E8sz0wD4bvVh/cRC4m8Px4x1hfN3kGO9+0PIJHF+j+mJuScSUeKcB3ykqlsB2j4BROQvwEud7dSTkTy1Buwf2YQsG7reGZdYbEcDAGV4V+L8LIRt22gp3pU4j9jYLTZaqJ61OfVdxf6XjZ1tQwLCVyTCODOIqKa1hb51V7+AE9kzqUh/sG6y8O214E/JPruLBdad7n+3ez3SAPj+2+e0cR4EPJpJ3rrKwhpmIf8SD+4GBzlZsKZaWJWWE2c2TuIyjhv29izgmxHJvxaR8TiB1td1yEsKug3sW1KgxLklBUqcO0JOG8fLEuehFChx3lHsV1KkxFHVBqC0Q9rlUTZPGtIfrP90S5w/eyTCAutXbonzG480EFHiPIR3Jc6VESXOp95okJMFa4pb4rwY//HSYuRAd9FtYP/Y7VUr8UiE7WgAHA1elTg/d0ucPnhX4jxqY7faaL6CR8GK9F3Ffs3GDtiQgHm1MtI4UgbW9W6J85BHIiyw7nBLnN95pAHw3eI+x3kU757jXG5hDbWQ1wSWe6NBJgnWqRbWaoG4xrE4ZKRxdAfYv3RLnAT02ceE7WgAHA1elTj3us9x8vFu5MAs9zlOjoJHs9nrB4r9bxvbn5h2VkYaR0rA+qY7cuB/PRJhgXWDe6f+xSMNgO87bonzFLDHGw3WxRbWYAt5S+AzbzTIMYJ1koW1VuC1+I+XkcbRXWA/YGOL7Vm9HtvRADgaPCpx7EfcEsdLDS+5Giz1rNTTjxV7iY0tmpB7IiONI8VgXWAhzRY865EIC6wvu3fJUwfetCeRyyysLAuZDTQcdPMewTrTwhpgIQsE1nijQQ4VrOMspErg7fiPl5HG0d1gP2+jansowtHgNfqSU/Jqk4ca3rGxfTba4t1cTLpasTfaaCgxGtJiYqn7f3cpYw/t+gtpWdrM4JbVhMTHhsDYuPXFhjKi2elCWpt9uEcaYFjLCiy12RgYTVC8aZkPaF1Prt3Adv8gdvu8GXVbFNpJaXALDVYh27KGdGmfc876XdSJpdLCOC+/fBLHmlenDUlmwICX03tGtvUPbiX3EI8eexsMnZAWxtk+r44tgUavZRgMYUxcNYMhBtKixDnknL4MHmgmzzUkmburo2alhXEGf6WM0aZzwJBs7l4SNSstjPPpshG0BAd4LcPQ64g+GjQtjPO3f5zerbhqBkNi6DRcBmA6BwyGmOiScUTkYRHZJiKfRKSViMirIrLK/ezrpouI3C8ilSKyVESO7SnxBoNXdLXEeRQ4t0PaLcDrqjoaeN1dByfqzWh3uQYnXJTBkFF0yTiqOg/Y2SF5GvuC6z4GfD4i/XF1eA/oIyIDEyHWYEgV4mnjHBIRBmoL0DYKsxzYGLFdlZvWjp4MSGgw9DQJ6VVTVe1uUMGeDEhoMPQ08ZQ4W9uqYO5n25zqm4DIcduD3TSDIWOIxzizga+5378GvBCRfoXbuzYJqIuo0hkMGUGXqmoi8hQwBegnIlXAfwN3Ak+LyFXAeuBSd/OXgfOBSmAvznw5BkNG0SXjqOqMKFlndLKtAtfGI8pgSHXMyAGDIQaMcQyGGDDGMRhiwBjHYIiBtHitwBA78+ddSijoxL495oQHyM8f5rGizMCUOBlOa8tOWtxl8fvXsbt+ldeSMgJjnAzmg3e/TjC4N7ze3FyD2i0eKsocjHEymIY9axk/4bccN+lBAtmlB9/B0GVMGyeDOfq4e9mw7glsu4Vgq0ezSmUoxjgZTN/S45gx6Un8lg0cwXMLz4GcrsVNNhwYY5wM57Rj+pMbaAZg4ZYT2VJX5LGizMC0cTKQiyf8k4snzMFnhZj90Zk0tQaYs+Q06hu9mtcx8zAlTgZy2pQSRJQXF8P8yuMI+FspGDKRqeW5vDO/hdo6895gvBjjZCDWwDN4460WbNupotklp3DqaTnk5wm5ucLrc5vZVWvMEw+mqpah1NTYKHDChCwuutAxDcCUUwKU9TM/e7yYEidDmX5JLi2tcOmXcsgOeDRrbgZj/vVkMFd8OZc1a0MEg6ZalmgOapwoUTzvEpEVbqTO50Skj5s+XEQaRWSxu/ypJ8UbOmf1mhCqypq1QV6b28zKVSFaW415EklXSpxH2T+K56vAEap6FPAZcGtE3mpVHe8u30qMTEN3+O0f9rJho80zLzRz9dfzeOPNZvbuNcZJJAc1TmdRPFX1X6oadFffwwkBZUgh7vptA1++NIdAAL777XyKi52feucum5ZWj8VlAIlo41wJzIlYHyEii0TkLRE5JdpOyYrkqWrT1LQtvPQmfnV3A1u32di2U9rU77Z58ulGqjaFPFaW/sRlHBG5DQgCT7hJm4GhqnoMcAPwpIh0OsZDVWeq6oRo02EnilBwL+++eZG7TKOlpZZUmKI+Wfzi1w1sq3HM8+CjjUy7IIeK4T6vZaU9MRtHRL4OXAh8xQ0Jhao2q+oO9/uHwGpgTAJ0xkx2tpCXl+cuuXz03sVeykk6oeBe7vhFDdXVDXzzSijp20TINiXO/ijQ3GGJTkzPcUTkXOAm4DRV3RuRXgbsVNWQiFTgTPWxJpZzJIKCfPjp7aWI9QEAajuV+xtuafJKUtJ5582LCAb3cPZr+9LGH/97Skp7tKBPMxRoIMe611lTgAOXygc1TpQonrcC2cCrIgLwntuDdirwUxFpBWzgW6racXqQpLFz504mTLiMU874J6oh3vzXqQBMPWc+ru6MRgQsy8Ky2lcsMv/Ku8sesuW3qLb9ZYRmvQ14MeoeBzVOlCieD0XZ9hngmS4oTQqB7BJOOu055r5ystdSPOGeXxUSCLy3X/r9f2zgs0pTXdtHIc16e7f2yPghNwV5fpb89Tx3TfjB/97eK0qb++4qxOfL/Ov0il4x5EZEwmbpDaa5/+5C2mpn/3lbPfW77XDeXb81pU0iyHjjNLVmc9OsmwnZFjc++WOv5SQFkYh/EBE977+8aw/rNxjTJIKMNw4ILcEAtz59Mzff0MKtNzbR7m7KQK6/eTehkHLTbfXcfmsBhQWOiWz7IDsaukwvMA74fHD9d0NkZUFWFtx0fTOZPHtiMAg3/3g3P77FMU1vqJ4mm15hHBHIzt63npMdfdtMoakZcrLbm+b67+YzuLxX/OQ9Tsb/FQNZyrVXO0+BVeG+P2bTW0bc/OzOPTQ27bvY/DzBZ0bbJISMN44IFBfvW6+rdz6//R8tWFZmO2hXrXLXbxrY07CvcXPlFXkMH2rcEy8Zb5xo9CvNbNO0sa3G5ncP7KWuzjFPaYlFIOCxqAyg1xnnihmt/PWprF5TXQPYVG0TNL3QCSVjRw7k5SmfO6+VyGFaIjBsqM26XmYcgNtvvx10F6MP/R5basq9lpP2ZKxxsvwwdrR5cNHGjtoTCIUaWfXyEwwe+kXyCyq8lpTWZKxxxBIKCgoIBuHZF5oQCy75Qo6bG6SwsACR4AGPkUmUHTIFgI3r/05z805jnDjJWOM0NcGrb1gEg/D+h7Cu8s/s2Nr2AOcqXp1rmSfphpjJcOM4s4/5LDjz9PZPPV97o3fOTDZw0Pnk5A7wWkbak7HGacPng1NOyuNLX7gBAFXluzfuZvJJWbwzv7XXdRIMHvYlryVkBBnfHZ3lhy+F2zYOE471c9kXc7Ay/uoNPUWskTzvEJFNERE7z4/Iu1VEKkVkpYic01PCu4oCzc3N4aWlpYUZl/hoaemdVTVDYuhKVe1R4PfA4x3Sf6Oqd0cmiMjhwHRgHDAIeE1ExqiqJ4/fLEsZOtimrq5uv7x16y1UszBv4BtiIaZIngdgGjDLDRO1FqgEJsahLy5yc2DGJfuHrazeLDz+VBa2bUxjiI14avnXuUHXHxaRvm5aObAxYpsqN20/khXJsw1VqNkuqMKDjwUwJY0hHmI1zgPASGA8TvTOe7p7gGRF8nTOBbV1wpNPO6Mbi4og098CNfQsMRlHVbeqakhVbeAv7KuObQIi5wMf7KYlHRElN9cxRzAIf/hzgO9/pxkR+IH7aTDESkzGEZGBEatfANp63GYD00UkW0RG4ETyfD8+ibFRVAjfudr0nBl6hlgjeU4RkfE49Z11wDcBVPVTEXkaWIYTjP1ar3rUOiMYBL97xX4ftAYV09YxxEJXetVmqOpAVc1S1cGq+pCqXq6qR6rqUap6kapujtj+F6o6UlXHquqcAx27p4kci2ar8Mu79w27ufWHzeYBqCFmMvbWqasXfvP7bHdKj30dAarqLt5pM6Q/aTRWrft3+p4G+O+fh/j33POZcvZbqCpTp04FYOo577odBMZBhu6TFsaZcej/MGZgXrf22VbfwlV/WAZAwC9cf8y3UWDuK07+3FdO4rmbj8ZvmTaOoXPe+Gf0vLQwDmi3u4/7F2Xx+HfHccXvPgWc16Yj62fP33wUPgvTLW2ICUmFaf3kIGE1fZbEfIMHQ86h/W7k/o7rBkM0giH9MNoD+rQocX42o4JRA7pXVTMY4uXSez6OmpcWxsnOssjLNkH0DKlDxnZHGww9iTGOwRADaVFVu3f2BrKzjMcNqUNaGOfzE8sY0i/n4BsaDAnklv+tjJqXFsapGJDL2EH5XsswGMKkhXHKTyyi4rAir2UYehu/jJ6VFsapfa2Wmo/NuzWG1CEtjFMzt47iQKPXMgyGMKarymCIAWMcgyEGuvLq9MPAhcA2VT3CTfsbMNbdpA9Qq6rjRWQ4sBxY6ea9p6rfildk6eQiBvTPjfcwBkP3mFkdNSumSJ6qelnbdxG5B4gMlblaVcd3W+QB2HxkFrkVvWCOdUNqMTN61kGNo6rz3JJkP0REgEuB02NT1jWeuHMNeebFGUMKEW+v2inAVlVdFZE2QkQWAfXAj1X17c52FJFrgGu6cpJvFBczykyVbEgyM6rjq6od8NjAUxHrm4GhqrpDRI4DnheRcapa33FHVZ2JWxge7EW2WBA/5A7NaTsZe9c2A5BXsW/ozt41TYk+7X60O9/aJlDIG5YN7ot0TVXN2C09+zJh7rBspO18m5qxm5XsAVn48pxXNVp3ttJa27NRvLIPycKX755vVyutu0L4C30EyrIAsJtsmqp79lmdv8BHoL97vmabpk0tiF/IHY78oykAAAozSURBVOo2AyLuk4MeK1YRIuIHLgaOa0tT1Wag2f3+oYisBsYASYkPHUmgLIuJfxtL89ZWskr9zDtxKQic8I9DadzUTM6gAG+dsBQN9uxNO/HvY2mqbnHOd+JStEU55uHR2M02gdIsPvzaZ+xZ0bPPqI59cBR2qxIo9fPRlZXs/nQvo28aTPHR+VhZwvpHtrLhkW09qmHUjeX0Oa4AK0vY+NdtrPvLVsrOKGb0D8sJ7rVp3NjMoquijw1LBP2mFDHm1iEEG0I0Vbfw0ddXkX2Ie59sayWrj595Jy/t0rHi6Y4+E1ihqlVtCSJSJiI+93sFTiTPNXGcIy5aa4O8f9mKdmmqynufW57U4DbvfW45dJhv9KNvrKJpU9f+uyWCRVdV0rih/fkq793Elv/r6kQU8bP6/mo2v7CjXdqOf9ez4o4NSdOwc349y29f3y6tZWeQD2asjLJH53RlYqmngPnAWBGpEpGr3KzptK+mAZwKLBWRxcA/gG+pavJ+GYMhSXSlV21GlPSvd5L2DPBM/LIMhtSmV4wciGzHeBXJ2g5quHqoEd+TiYbYFyIr5JEG21k6fk+uCNBQ5D3R/T9EWgzyjBmB0F6bt0/9OBxb/a0TliQ/zroF805aGtb07rmfhr8nDWFfPV7gk5vWAVB0ZPKiB4nA6t9WhzVseXEnW17cSclJhUnTALDrgz3s+qASBJqqW5h/wTL8Rd0LBpO5xlHI6utnysKjvVbClA+81zDpxcOi5q35/eaoeYlk7O1DGHv7kE7z6hY1JEVDv6nFUe8Ju6nrJU9aBCT8Wb9+5gGoIenMqK6OGpAwLYxjBtsYvEAhvSN5KtcDw2LeP0uCzJx4J4pw5YLbEiesm8yceCdZEuS7H97AnqA3kUlvH/cwFQXV3P/ZpSzaNcYTDZ8f/BbTyt9m3rbxPLL2Qk80jCyo4sfjHmVbc19uXnxtlK1+EHX/tDAO+IhPquK3xO1Q8u6S/QJ+S5C4ryd2fCKuBsszDRYWfkuwxDsNgg+/JfiFmDT0iu5ogyHRGOMYDDGQFlW1Pn0L8Wf1iXn/LGkNf+/XP/bjxI/TzVFaVkx2qMATBf4s5ycv6lNAvzj+pvGQl++MGM/JDXj2e/TJqQXA8vmiath+gHGvaWEcy2fh98c+W4FP9j2ejuc4ceN2D/p8PvzijY629wEtSzz7W1jurMUi8f2uCdFAbPdEWnRHDxt5D7m5Yw+0SVQCgRau/sZfeenRqYjA5658jd/98WqS3cl93bce5OXHpxAKWZz7lXk88fSX2LMnuaXOV6b/nU//PZpdNUVMPHMJH1cewYqVo5Oq4ZST55Mb2svKRSMYNraavAHN/PNfZyRVw5AhVZx2wru8/eIE8gsbOfGCRTz02Ff3227FJxemd3e03+8jK9B9qXl5TXzv2hcYMayWmY+MAVUmHv80t936LHfdeymqyTHPTTc8zaFjd/DQ46MIqp+jj3mJgeX/xx9nfo5du5ITofSb//ES44+u4oOPTqVayxkyejHHT36HfzznZ9Hi5JjnvLPf58zTl/LW20dR/dEYRpY2cNGF8+hbkss/nj01KRpGj6riqzPm0tIi/G32GMoCu5g8eQ59Sl7k/j98ocvHSQvj5OfnUljU/ecehYXKkePWY9vC977zHAhkZ/s5+si1FBXnoXZyjHPUkWsQ8XHtt2ajtlBcFKJf6UZKS/2EQsl5njPusCqKCkNMv3QeDXtyGDN6G3377mFweROr1yRHw4iKWgYM2M3JJ61k+LDtlJXV0a9fI6NH1VAUw+8bCwMHBhk1ciu79+Twve88R3ZOK/n5cMS49d3SkBbGCQT8ZOd0f8iNrcIzz0/j65fP4cwz1rYdjZkPf45AIECyqmuz/v5Frr7yJc6Yus5N8fHE386huaUkpuuKhRfnnM9Xp7/CiSfsG5c2d94JrF0/NmkaPvzoeMoH7eXIcWs47FDnbfo1a4fz9junJE3Dlq3DmPfOqVxw7nsMGujcE3v3FvLsC+d3S0NaGCdWgsEs5i84noIOg28XfDCBZLZxFiw8nr4lISKbcu++dyxNTckLebV46VEUFioFBXvDaUs/HsXWbWVJ07Bm3QheeVVYuWpfe3XzllJWrkreCIZdtX15698n0djUN5zW3Bzgw0XHdOs4adE5cNykhyjuMy5ZcgwGAN7456SonQNdeXV6iIjMFZFlIvKpiHzfTS8RkVdFZJX72ddNFxG5X0QqRWSpiBwb7wWYQZ6GVKMrIweCwI2qejgwCbhWRA4HbgFeV9XRwOvuOsB5OEE6RuPETXsg4aoNBo/pSsyBzTjx0lDV3SKyHCgHpgFT3M0eA94EbnbTH1enDvieiPQRkYHucWJi546FNDVtiXV3gyHhdKtzwA2FewywADgkwgxbgEPc7+XAxojdqty0dsbpTiTPNatMoWVILbo8yFNECnAi2PygY2ROt3TpVi+Dqs5U1QnRGl8GQyrTJeOISBaOaZ5Q1Wfd5K0iMtDNHwi0DYnbBES+WD7YTTMYMoau9KoJ8BCwXFXvjciaDXzN/f414IWI9Cvc3rVJQF087RuDISVR1QMuwGScathSYLG7nA+U4vSmrQJeA0rc7QX4A7Aa+BiY0IVzqFnMkoLLwmj3bFo8ADUYPCL2B6AGg2F/jHEMhhgwxjEYYsAYx2CIgVR5rWA70OB+Zgr9yJzryaRrga5fz7BoGSnRqwYgIgszaRRBJl1PJl0LJOZ6TFXNYIgBYxyDIQZSyTgzvRaQYDLpejLpWiAB15MybRyDIZ1IpRLHYEgbjHEMhhjw3Dgicq6IrHSDe9xy8D1SDxFZJyIfi8hiEVnopnUazCQVEZGHRWSbiHwSkZa0YCyJJsr13CEim9zfaLGInB+Rd6t7PStF5JwuneRgQ/57csGZMWo1UAEEgCXA4V5qivE61gH9OqT9GrjF/X4L8D9e6zyA/lOBY4FPDqYf55WSOTivj0wCFnitv4vXcwfww062Pdy977KBEe796DvYObwucSYClaq6RlVbgFk4wT4ygWk4QUxwPz/voZYDoqrzgJ0dkqPpDwdjUdX3gD5tbwKnClGuJxrTgFmq2qyqa4FKnPvygHhtnGiBPdINBf4lIh+6QUggejCTdKG7wVjSgevc6uXDEVXnmK7Ha+NkCpNV9VicmHLXiki70Pvq1AnStt8/3fW7PACMBMbjRFy6J56DeW2cjAjsoaqb3M9twHM4RX20YCbpQkYFY1HVraoaUlUb+Av7qmMxXY/XxvkAGC0iI0QkAEzHCfaRNohIvogUtn0HzgY+IXowk3Qho4KxdGiHfQHnNwLneqaLSLaIjMCJQPv+QQ+YAj0g5wOf4fRm3Oa1nhj0V+D0yiwBPm27BqIEM0nFBXgKp/rSilPHvyqafmIIxpIi1/NXV+9S1ywDI7a/zb2elcB5XTmHGXJjMMSA11U1gyEtMcYxGGLAGMdgiAFjHIMhBoxxDIYYMMYxGGLAGMdgiIH/B/E2Hk4qUA1sAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejdlsSzJovVP"
      },
      "source": [
        "# Build an agent\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We now have to build an agent for actor-critic training - a convolutional neural network that converts states into action probabilities and state values .\n",
        "\n",
        "Your assignment here is to build and apply a neural network - with any framework you want.\n",
        "\n",
        "For starters, we want you to implement this architecture: \n",
        "\n",
        "After you get above 50 points, we encourage you to experiment with model architecture to score even better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Qg7FRfkokL",
        "outputId": "57093f53-ebb5-4161-ba12-0fcd4bc10755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.reset_default_graph()\n",
        "sess = tf.compat.v1.InteractiveSession()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1771: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRb-25lKoAjy"
      },
      "source": [
        "from keras.layers import Conv2D, Dense, Flatten, Input\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, state_shape, n_actions, reuse=False):\n",
        "        \"\"\"A simple actor-critic agent\"\"\"\n",
        "        \n",
        "        with tf.compat.v1.variable_scope(name, reuse=reuse):\n",
        "            ####\n",
        "            inputs = Input(shape=state_shape)\n",
        "            x = Conv2D(32, (3, 3), strides=2, activation='relu')(inputs)\n",
        "            x = Conv2D(32, (3, 3), strides=2, activation='relu')(x)\n",
        "            x = Conv2D(32, (3, 3), strides=2, activation='relu')(x)\n",
        "            x = Flatten()(x)\n",
        "            x = Dense(128, activation='relu')(x)\n",
        "            \n",
        "            # two different output layers\n",
        "            logits = Dense(n_actions, activation='linear')(x)\n",
        "            state_value = Dense(1, activation='linear')(x)\n",
        "            \n",
        "            self.network = Model(inputs=inputs, outputs=[logits, state_value])\n",
        "            \n",
        "            \n",
        "            # prepare a graph for agent step\n",
        "            self.state_t = tf.compat.v1.placeholder('float32', [None,] + list(state_shape))\n",
        "            self.agent_outputs = self.symbolic_step(self.state_t)\n",
        "        \n",
        "    def symbolic_step(self, state_t):\n",
        "        \"\"\"Takes agent's previous step and observation, returns next state and whatever it needs to learn (tf tensors)\"\"\"\n",
        "        \n",
        "        # Apply neural network\n",
        "        ### Apply agent's neural network to get policy logits and state values.\n",
        "#         network_output = self.network(state_t)\n",
        "\n",
        "#         logits = network_output[:,1:]\n",
        "#         state_value = network_output[:,0]\n",
        "        \n",
        "        \n",
        "        logits, state_value = self.network(state_t)\n",
        "        state_value = state_value[:, 0]\n",
        "        \n",
        "        assert tf.compat.v1.is_numeric_tensor(state_value) and state_value.shape.ndims == 1, \\\n",
        "            \"please return 1D tf tensor of state values [you got %s]\" % repr(state_value)\n",
        "        assert tf.compat.v1.is_numeric_tensor(logits) and logits.shape.ndims == 2, \\\n",
        "            \"please return 2d tf tensor of logits [you got %s]\" % repr(logits)\n",
        "        # if you triggered state_values assert with your shape being [None, 1], \n",
        "        # just select [:, 0]-th element of state values as new state values\n",
        "        \n",
        "        return (logits, state_value)\n",
        "    \n",
        "    def step(self, state_t):\n",
        "        \"\"\"Same as symbolic step except it operates on numpy arrays\"\"\"\n",
        "        sess = tf.compat.v1.get_default_session()\n",
        "        return sess.run(self.agent_outputs, {self.state_t: state_t})\n",
        "    \n",
        "    def sample_actions(self, agent_outputs):\n",
        "        \"\"\"pick actions given numeric agent outputs (np arrays)\"\"\"\n",
        "        logits, state_values = agent_outputs\n",
        "        policy = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
        "        return np.array([np.random.choice(len(p), p=p) for p in policy])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updating hyper parameters\n"
      ],
      "metadata": {
        "id": "pwSNyBPU5WYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Dense, Flatten, Input\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, state_shape, n_actions, reuse=False):\n",
        "        \"\"\"A simple actor-critic agent\"\"\"\n",
        "        \n",
        "        with tf.compat.v1.variable_scope(name, reuse=reuse):\n",
        "            ####\n",
        "            inputs = Input(shape=state_shape)\n",
        "            x = Conv2D(512, (3, 3), strides=1, activation='relu')(inputs)\n",
        "            x = Conv2D(512, (3, 3), strides=1, activation='relu')(x)\n",
        "            x = Conv2D(512, (3, 3), strides=1, activation='relu')(x)\n",
        "            x = Flatten()(x)\n",
        "            x = Dense(512, activation='softmax')(x)\n",
        "            \n",
        "            # two different output layers\n",
        "            logits = Dense(n_actions, activation='linear')(x)\n",
        "            state_value = Dense(1, activation='linear')(x)\n",
        "            \n",
        "            self.network = Model(inputs=inputs, outputs=[logits, state_value])\n",
        "            \n",
        "            \n",
        "            # prepare a graph for agent step\n",
        "            self.state_t = tf.compat.v1.placeholder('float32', [None,] + list(state_shape))\n",
        "            self.agent_outputs = self.symbolic_step(self.state_t)\n",
        "        \n",
        "    def symbolic_step(self, state_t):\n",
        "        \"\"\"Takes agent's previous step and observation, returns next state and whatever it needs to learn (tf tensors)\"\"\"\n",
        "        \n",
        "        # Apply neural network\n",
        "        ### Apply agent's neural network to get policy logits and state values.\n",
        "#         network_output = self.network(state_t)\n",
        "\n",
        "#         logits = network_output[:,1:]\n",
        "#         state_value = network_output[:,0]\n",
        "        \n",
        "        \n",
        "        logits, state_value = self.network(state_t)\n",
        "        state_value = state_value[:, 0]\n",
        "        \n",
        "        assert tf.compat.v1.is_numeric_tensor(state_value) and state_value.shape.ndims == 1, \\\n",
        "            \"please return 1D tf tensor of state values [you got %s]\" % repr(state_value)\n",
        "        assert tf.compat.v1.is_numeric_tensor(logits) and logits.shape.ndims == 2, \\\n",
        "            \"please return 2d tf tensor of logits [you got %s]\" % repr(logits)\n",
        "        # if you triggered state_values assert with your shape being [None, 1], \n",
        "        # just select [:, 0]-th element of state values as new state values\n",
        "        \n",
        "        return (logits, state_value)\n",
        "    \n",
        "    def step(self, state_t):\n",
        "        \"\"\"Same as symbolic step except it operates on numpy arrays\"\"\"\n",
        "        sess = tf.compat.v1.get_default_session()\n",
        "        return sess.run(self.agent_outputs, {self.state_t: state_t})\n",
        "    \n",
        "    def sample_actions(self, agent_outputs):\n",
        "        \"\"\"pick actions given numeric agent outputs (np arrays)\"\"\"\n",
        "        logits, state_values = agent_outputs\n",
        "        policy = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
        "        return np.array([np.random.choice(len(p), p=p) for p in policy])"
      ],
      "metadata": {
        "id": "v9wsyTNc5Z7f"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtQetyEoHMD"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "agent = Agent(\"agent\", obs_shape, n_actions)\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRUs5NBuoNWB",
        "outputId": "49b8596e-318b-4d33-ab03-e10ffae67694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "state = [env.reset()]\n",
        "logits, value = agent.step(state)\n",
        "print(\"action logits:\\n\", logits)\n",
        "print(\"state values:\\n\", value)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action logits:\n",
            " [[-0.00067229 -0.00118249  0.0011263   0.00209706 -0.00136463 -0.00249082\n",
            "   0.00293977 -0.00081808  0.00040094  0.00611593  0.00148805 -0.00216797\n",
            "  -0.00156517 -0.00131315  0.00339136  0.00321248 -0.00124102  0.00051605]]\n",
            "state values:\n",
            " [0.00147345]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OqIoeqmo4n5"
      },
      "source": [
        "# Let's play!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Let's build a function that measures agent's average reward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AFcqPHKoQ_i"
      },
      "source": [
        "def evaluate(agent, env, n_games=1):\n",
        "    \"\"\"Plays an a game from start till done, returns per-game rewards \"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        state = env.reset()\n",
        "        \n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            action = agent.sample_actions(agent.step([state]))[0]\n",
        "            state, reward, done, info = env.step(action)\n",
        "            total_reward += reward\n",
        "            if done: break\n",
        "                \n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUPl5-sKoVpg"
      },
      "source": [
        "env_monitor = gym.wrappers.Monitor(env, directory=\"kungfu_videos\", force=True)\n",
        "rw = evaluate(agent, env_monitor, n_games=3,)\n",
        "env_monitor.close()\n",
        "print (rw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcr9OW2IoZU1"
      },
      "source": [
        "from IPython.display import HTML\n",
        "import os\n",
        "\n",
        "# needed to import code to fix issue with video also changed the dir to remove \n",
        "# underscore\n",
        "# ref for this code below https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab\n",
        "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./kungfu_videos/\")))\n",
        "from base64 import b64encode\n",
        "mp4 = open(\"./kungfu_videos/\"+video_names[0],'rb').read()\n",
        "agent_video = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=%s type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" %agent_video) #this may or may not be _last_ video. Try other indices\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MmDLcuUpGMj"
      },
      "source": [
        "# Training on parallel games\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/f894eba2ee745652f1fc95484cfa45bf26decb8e/68747470733a2f2f6769746875622e636f6d2f79616e646578646174617363686f6f6c2f50726163746963616c5f524c2f7261772f6d61737465722f7965745f616e6f746865725f7765656b2f5f7265736f757263652f2f656e765f706f6f6c2e706e67)\n",
        "\n",
        "To make actor-critic training more stable, we shall play several games in parallel. This means ya'll have to initialize several parallel gym envs, send agent's actions there and .reset() each env if it becomes terminated. To minimize learner brain damage, we've taken care of them for ya - just make sure you read it before you use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX-uaGwCojPt"
      },
      "source": [
        "class EnvBatch:\n",
        "    def __init__(self, n_envs = 10):\n",
        "        \"\"\" Creates n_envs environments and babysits them for ya' \"\"\"\n",
        "        self.envs = [make_env() for _ in range(n_envs)]\n",
        "        \n",
        "    def reset(self):\n",
        "        \"\"\" Reset all games and return [n_envs, *obs_shape] observations \"\"\"\n",
        "        return np.array([env.reset() for env in self.envs])\n",
        "    \n",
        "    def step(self, actions):\n",
        "        \"\"\"\n",
        "        Send a vector[batch_size] of actions into respective environments\n",
        "        :returns: observations[n_envs, *obs_shape], rewards[n_envs], done[n_envs,], info[n_envs]\n",
        "        \"\"\"\n",
        "        results = [env.step(a) for env, a in zip(self.envs, actions)]\n",
        "        new_obs, rewards, done, infos = map(np.array, zip(*results))\n",
        "        \n",
        "        # reset environments automatically\n",
        "        for i in range(len(self.envs)):\n",
        "            if done[i]:\n",
        "                new_obs[i] = self.envs[i].reset()\n",
        "        \n",
        "        return new_obs, rewards, done, infos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JawlpBFo0Yb"
      },
      "source": [
        "env_batch = EnvBatch(10)\n",
        "\n",
        "batch_states = env_batch.reset()\n",
        "\n",
        "batch_actions = agent.sample_actions(agent.step(batch_states))\n",
        "\n",
        "batch_next_states, batch_rewards, batch_done, _ = env_batch.step(batch_actions)\n",
        "\n",
        "print(\"State shape:\", batch_states.shape)\n",
        "print(\"Actions:\", batch_actions[:3])\n",
        "print(\"Rewards:\", batch_rewards[:3])\n",
        "print(\"Done:\", batch_done[:3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwEPCL46pfHO"
      },
      "source": [
        "# Actor-critic\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here we define a loss functions and learning algorithms as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C6zD_V1o35d"
      },
      "source": [
        "# These placeholders mean exactly the same as in \"Let's try it out\" section above\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "states_ph = tf.compat.v1.placeholder('float32', [None,] + list(obs_shape))    \n",
        "next_states_ph =  tf.compat.v1.placeholder('float32', [None,] + list(obs_shape))\n",
        "actions_ph =  tf.compat.v1.placeholder('int32', (None,))\n",
        "rewards_ph =  tf.compat.v1.placeholder('float32', (None,))\n",
        "is_done_ph =  tf.compat.v1.placeholder('float32', (None,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktpq6pJgo-Dl"
      },
      "source": [
        "# logits[n_envs, n_actions] and state_values[n_envs, n_actions]\n",
        "logits, state_values = agent.symbolic_step(states_ph)\n",
        "next_logits, next_state_values = agent.symbolic_step(next_states_ph)\n",
        "next_state_values = next_state_values * (1 - is_done_ph)\n",
        "\n",
        "# probabilities and log-probabilities for all actions\n",
        "probs = tf.nn.softmax(logits)            # [n_envs, n_actions]\n",
        "logprobs = tf.nn.log_softmax(logits)     # [n_envs, n_actions]\n",
        "\n",
        "# log-probabilities only for agent's chosen actions\n",
        "logp_actions = tf.reduce_sum(logprobs * tf.one_hot(actions_ph, n_actions), axis=-1) # [n_envs,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-aNY8wRpBk9"
      },
      "source": [
        "\n",
        "\n",
        "# compute advantage using rewards_ph, state_values and next_state_values\n",
        "gamma = 0.99\n",
        "advantage = rewards_ph + gamma*next_state_values - state_values\n",
        "\n",
        "assert advantage.shape.ndims == 1, \"please compute advantage for each sample, vector of shape [n_envs,]\"\n",
        "\n",
        "# compute policy entropy given logits_seq. Mind the \"-\" sign!\n",
        "entropy =  -tf.reduce_sum(probs * logprobs, 1, name=\"entropy\")\n",
        "\n",
        "assert entropy.shape.ndims == 1, \"please compute pointwise entropy vector of shape [n_envs,] \"\n",
        "\n",
        "\n",
        "\n",
        "actor_loss =  - tf.reduce_mean(logp_actions * tf.stop_gradient(advantage)) - 0.001 * tf.reduce_mean(entropy)\n",
        "\n",
        "# compute target state values using temporal difference formula. Use rewards_ph and next_step_values\n",
        "target_state_values = rewards_ph+gamma*next_state_values\n",
        "\n",
        "critic_loss = tf.reduce_mean((state_values - tf.stop_gradient(target_state_values))**2 )\n",
        "\n",
        "train_step = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(actor_loss + critic_loss)\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9qCcr3cpEtw"
      },
      "source": [
        "# Sanity checks to catch some errors. Specific to KungFuMaster in assignment's default setup.\n",
        "l_act, l_crit, adv, ent = sess.run([actor_loss, critic_loss, advantage, entropy], feed_dict = {\n",
        "        states_ph: batch_states,\n",
        "        actions_ph: batch_actions,\n",
        "        next_states_ph: batch_states,\n",
        "        rewards_ph: batch_rewards,\n",
        "        is_done_ph: batch_done,\n",
        "    })\n",
        "\n",
        "assert abs(l_act) < 100 and abs(l_crit) < 100, \"losses seem abnormally large\"\n",
        "assert 0 <= ent.mean() <= np.log(n_actions), \"impossible entropy value, double-check the formula pls\"\n",
        "if ent.mean() < np.log(n_actions) / 2: print(\"Entropy is too low for untrained agent\")\n",
        "print(\"You just might be fine!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGMW7v42peBa"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAFWsGKlpuIM"
      },
      "source": [
        "# Train\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Just the usual - play a bit, compute loss, follow the graidents, repeat a few million times.\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/69cc1e7cffa2ebd5db67c39f7c7c2724aaf5594b/687474703a2f2f696d61676573362e66616e706f702e636f6d2f696d6167652f70686f746f732f33383930303030302f44616e69656c2d73616e2d747261696e696e672d7468652d6b61726174652d6b69642d33383934373336312d3439392d3238382e676966)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6TQ0p8ul1ZA"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpqugPcIpIlq"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange\n",
        "import pandas as pd\n",
        "#from pandas import ewm\n",
        "\n",
        "env_batch = EnvBatch(10)\n",
        "batch_states = env_batch.reset()\n",
        "\n",
        "rewards_history = []\n",
        "entropy_history = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-uNJ4-TpNC_"
      },
      "source": [
        "for i in trange(100000): \n",
        "    \n",
        "    batch_actions = agent.sample_actions(agent.step(batch_states))\n",
        "    batch_next_states, batch_rewards, batch_done, _ = env_batch.step(batch_actions)\n",
        "    \n",
        "    feed_dict = {\n",
        "        states_ph: batch_states,\n",
        "        actions_ph: batch_actions,\n",
        "        next_states_ph: batch_next_states,\n",
        "        rewards_ph: batch_rewards,\n",
        "        is_done_ph: batch_done,\n",
        "    }\n",
        "    batch_states = batch_next_states\n",
        "    \n",
        "    _, ent_t = sess.run([train_step, entropy], feed_dict)\n",
        "    entropy_history.append(np.mean(ent_t))\n",
        "\n",
        "    if i % 500 == 0: \n",
        "        if i % 2500 == 0:\n",
        "            rewards_history.append(np.mean(evaluate(agent, env, n_games=3)))\n",
        "            if rewards_history[-1] >= 50:\n",
        "                print(\"Your agent has earned the yellow belt\")\n",
        "\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=[8,4])\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.plot(rewards_history, label='rewards')\n",
        "        df = pd.DataFrame(rewards_history)\n",
        "        plt.plot(df.ewm(halflife=1000).mean(), marker='.', label='rewards ewma@10')\n",
        "        plt.title(\"Session rewards\"); plt.grid(); plt.legend()\n",
        "        \n",
        "        plt.subplot(1,2,2)\n",
        "        plt.plot(entropy_history, label='entropy')\n",
        "        df2 = pd.DataFrame(entropy_history)\n",
        "        plt.plot(df2.ewm(halflife=1000).mean(), label='entropy ewma@1000')\n",
        "        plt.title(\"Policy entropy\"); plt.grid(); plt.legend()        \n",
        "        plt.show()\n",
        "        \n",
        "df = pd.DataFrame(data=batch_rewards)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC3JUqqPpo6k"
      },
      "source": [
        "env_monitor = gym.wrappers.Monitor(env, directory=\"kungfu_videos\", force=True)\n",
        "final_rewards = evaluate(agent, env_monitor, n_games=1,)\n",
        "env_monitor.close()\n",
        "print(\"Final mean reward:\", np.mean(final_rewards))\n",
        "\n",
        "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./kungfu_videos/\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVwb5QCk3YUb"
      },
      "source": [
        "df.ewm(halflife=12).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jghRDEjNThIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}